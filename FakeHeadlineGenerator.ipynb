{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeHeadlineGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharangw/FakeNewsGenerator/blob/master/FakeHeadlineGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah1t3kfLneKv",
        "colab_type": "code",
        "outputId": "cc885e65-cc78-4647-a91d-659778e7b370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIGREf8fsHsr",
        "colab_type": "code",
        "outputId": "85ab4063-7207-47dc-b156-0bd2caf5a146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND26A4ZXnm0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H4HqcY0nrNN",
        "colab_type": "code",
        "outputId": "da047e57-476d-4f5e-f0b5-90c258f60298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGYN-iire9N",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTr01tz-oNRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the data file\n",
        "\n",
        "df=pd.read_csv(\"drive/My Drive/Colab Notebooks/abcnews-date-text.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "957NJatxo622",
        "colab_type": "code",
        "outputId": "df0fbb62-58b5-449f-b1ab-5e3a5d12119e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030219</td>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030219</td>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20030219  aba decides against community broadcasting lic...\n",
              "1      20030219     act fire witnesses must be aware of defamation\n",
              "2      20030219     a g calls for infrastructure protection summit\n",
              "3      20030219           air nz staff in aust strike for pay rise\n",
              "4      20030219      air nz strike to affect australian travellers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj6Yogx8o-Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create a list containing the text of the articles\n",
        "\n",
        "y=[]\n",
        "for i in df.loc[:,\"headline_text\"].values:\n",
        "    y.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBNKGlEtq0UT",
        "colab_type": "code",
        "outputId": "18642df3-3628-4e2b-82f6-93cf6cc785f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y[0:4]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aba decides against community broadcasting licence',\n",
              " 'act fire witnesses must be aware of defamation',\n",
              " 'a g calls for infrastructure protection summit',\n",
              " 'air nz staff in aust strike for pay rise']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ2fnLo6pHsS",
        "colab_type": "code",
        "outputId": "4e510a24-7892-43fd-a3cc-b9c53bdb8d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1186018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOgoA6VnpI81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concatstr = ' '.join(y) ## take the contents of the list and put it into one giant string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZVGw8OepNVh",
        "colab_type": "code",
        "outputId": "9c8eb331-23e2-4f08-d75d-146974a26de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(concatstr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49546647"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UXTtxmgp-EQ",
        "colab_type": "text"
      },
      "source": [
        "Can Change This Number of Characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXK2-AgpPEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newinput = concatstr[0:15000000] # work with the first 30 million characters\n",
        "text = newinput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCph4UFkqEsW",
        "colab_type": "code",
        "outputId": "ea8130fd-51c9-4ac0-a674-743d278e2e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AEU-K7fqs5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXbjaRsdq_01",
        "colab_type": "code",
        "outputId": "35ea1eea-4d86-416a-a805-b3e85e1fa208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(120)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  ' ' :   0,\n",
            "  '.' :   1,\n",
            "  '0' :   2,\n",
            "  '1' :   3,\n",
            "  '2' :   4,\n",
            "  '3' :   5,\n",
            "  '4' :   6,\n",
            "  '5' :   7,\n",
            "  '6' :   8,\n",
            "  '7' :   9,\n",
            "  '8' :  10,\n",
            "  '9' :  11,\n",
            "  ';' :  12,\n",
            "  'a' :  13,\n",
            "  'b' :  14,\n",
            "  'c' :  15,\n",
            "  'd' :  16,\n",
            "  'e' :  17,\n",
            "  'f' :  18,\n",
            "  'g' :  19,\n",
            "  'h' :  20,\n",
            "  'i' :  21,\n",
            "  'j' :  22,\n",
            "  'k' :  23,\n",
            "  'l' :  24,\n",
            "  'm' :  25,\n",
            "  'n' :  26,\n",
            "  'o' :  27,\n",
            "  'p' :  28,\n",
            "  'q' :  29,\n",
            "  'r' :  30,\n",
            "  's' :  31,\n",
            "  't' :  32,\n",
            "  'u' :  33,\n",
            "  'v' :  34,\n",
            "  'w' :  35,\n",
            "  'x' :  36,\n",
            "  'y' :  37,\n",
            "  'z' :  38,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A42gwv98rBjd",
        "colab_type": "code",
        "outputId": "80b654d0-1cbd-4d9f-e85d-f3402bd9e1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:15]), text_as_int[:15]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'aba decides aga' ---- characters mapped to int ---- > [13 14 13  0 16 17 15 21 16 17 31  0 13 19 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pCbomV_ramS",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl2umsHQrDjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 200\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBW5Z1HIrH4O",
        "colab_type": "code",
        "outputId": "75b8e7a5-05b8-40fb-df2c-c4f4f983ccc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'aba decides against community broadcasting licence act fire witnesses must be aware of defamation a g calls for infrastructure protection summit air nz staff in aust strike for pay rise air nz strike t'\n",
            "'o affect australian travellers ambitious olsson wins triple jump antic delighted with record breaking barca aussie qualifier stosur wastes four memphis match aust addresses un security council over ira'\n",
            "'q australia is locked into war timetable opp australia to contribute 10 million in aid to iraq barca take record as robson celebrates birthday in bathhouse plans move ahead big hopes for launceston cyc'\n",
            "'ling championship big plan to boost paroo water supplies blizzard buries united states in bills brigadier dismisses reports troops harassed in british combat troops arriving daily in kuwait bryant lead'\n",
            "'s lakers to double overtime win bushfire victims urged to see centrelink businesses should prepare for terrorist attacks calleri avenges final defeat to eliminate massu call for ethanol blend fuel to g'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWuLJafDrLE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZU1e25irP0P",
        "colab_type": "code",
        "outputId": "bd1fc1b4-60de-4020-ce4f-3d7ed1e320fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((128, 200), (128, 200)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuQlOrC8rRA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZELp5_nrSbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWq3vuPxrT2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbvmtv0khA5K",
        "colab_type": "code",
        "outputId": "c99813c4-6d3b-45a0-f33e-78e509010346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 200, 39) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGz-V-YCrU_4",
        "colab_type": "code",
        "outputId": "976e12d3-93b1-4a7f-be61-dde410ca416c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (128, None, 256)          9984      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (128, None, 1024)         3935232   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (128, None, 1024)         6294528   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (128, None, 39)           39975     \n",
            "=================================================================\n",
            "Total params: 10,279,719\n",
            "Trainable params: 10,279,719\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCeJf7HxgpyU",
        "colab_type": "code",
        "outputId": "1bacc868-d8c3-47e6-e6d4-3d0cbd0703c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([38, 31, 34, 19, 37,  6, 33, 23, 14, 20,  1, 28, 20,  3, 37, 22, 26,\n",
              "       15,  0,  3, 20, 36, 22, 17, 13,  7, 30, 31, 24, 23, 33, 12, 34, 18,\n",
              "       26, 34, 15, 27, 14,  5,  3, 19,  9, 31, 37,  6, 14, 10, 14,  1, 32,\n",
              "       10, 25,  6,  3, 10, 38, 32, 23, 13, 17, 19, 22, 17, 37, 22, 38, 22,\n",
              "        1, 20, 18,  9, 11,  2, 26, 25,  5, 16, 37, 14, 12, 34, 36,  6, 35,\n",
              "       26, 22, 23, 24, 36,  9,  0, 10, 22, 17,  8,  6, 13, 31, 17, 32, 10,\n",
              "       18, 31, 11, 21,  5, 12, 23, 20, 38,  3, 29, 23, 10, 28, 20, 21,  8,\n",
              "        5, 10, 25,  7, 29, 38, 14,  6,  9, 18,  6, 17, 22,  2,  7, 10, 11,\n",
              "        2, 31, 23, 33, 11, 20,  5, 18, 38,  9, 25, 27, 17,  4, 10, 35, 15,\n",
              "       11, 18, 17, 36,  5, 26, 19, 38,  3, 12, 37, 13, 15, 20,  1, 14, 14,\n",
              "        0, 26, 20, 36, 33, 25, 23, 19, 18, 17, 23, 29, 16, 34,  4, 10, 11,\n",
              "       12, 22, 14, 14, 30, 34, 33, 20,  0, 31, 35, 33, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCgzm9chjQnA",
        "colab_type": "code",
        "outputId": "27bd2ac1-fe73-4630-86a8-4a34ac76267f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'decision to chop trees council feels fenced in over qr plan councillors urged to consider roles during court rules against minister in deportation case court to hear high rise concerns crean claims 15'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'zsvgy4ukbh.ph1yjnc 1hxjea5rslku;vfnvcob31g7sy4b8b.t8m418ztkaegjeyjzj.hf790nm3dyb;vx4wnjklx7 8je64aset8fs9i3;khz1qk8phi638m5qzb47f4ej05890sku9h3fz7moe28wc9fex3ngz1;yach.bb nhxumkgfekqdv289;jbbrvuh swud'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK2WSBHgrXhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwHFasoYrqG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og93rWb2rr8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUzFWGSBvtqG",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpOsIvrhrygD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGx8anvXr0ec",
        "colab_type": "code",
        "outputId": "bbc63e8d-66eb-4cc4-eb72-f022fb86cff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "583/583 [==============================] - 661s 1s/step - loss: 1.8660\n",
            "Epoch 2/15\n",
            "583/583 [==============================] - 656s 1s/step - loss: 1.2907\n",
            "Epoch 3/15\n",
            "583/583 [==============================] - 652s 1s/step - loss: 1.2075\n",
            "Epoch 4/15\n",
            "583/583 [==============================] - 652s 1s/step - loss: 1.1567\n",
            "Epoch 5/15\n",
            "583/583 [==============================] - 653s 1s/step - loss: 1.1189\n",
            "Epoch 6/15\n",
            "583/583 [==============================] - 657s 1s/step - loss: 1.0895\n",
            "Epoch 7/15\n",
            "583/583 [==============================] - 656s 1s/step - loss: 1.0670\n",
            "Epoch 8/15\n",
            "583/583 [==============================] - 656s 1s/step - loss: 1.0505\n",
            "Epoch 9/15\n",
            "583/583 [==============================] - 656s 1s/step - loss: 1.0378\n",
            "Epoch 10/15\n",
            "583/583 [==============================] - 657s 1s/step - loss: 1.0274\n",
            "Epoch 11/15\n",
            "583/583 [==============================] - 658s 1s/step - loss: 1.0187\n",
            "Epoch 12/15\n",
            "583/583 [==============================] - 659s 1s/step - loss: 1.0115\n",
            "Epoch 13/15\n",
            "583/583 [==============================] - 657s 1s/step - loss: 1.0054\n",
            "Epoch 14/15\n",
            "583/583 [==============================] - 658s 1s/step - loss: 0.9999\n",
            "Epoch 15/15\n",
            "583/583 [==============================] - 659s 1s/step - loss: 0.9949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N51fqudr3ss",
        "colab_type": "code",
        "outputId": "1c9de849-365b-42bb-817c-489f6712937a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndbP8YvNvZw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./training_checkpoints/ckpt_10.index') \n",
        "files.download('./training_checkpoints/ckpt_10.data-00000-of-00002') \n",
        "files.download('./training_checkpoints/ckpt_10.data-00001-of-00002')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmPu65S6vrLM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjNFerkTvagr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "# model.load_weights(tf.train.latest_checkpoint(checkpoint_dir)) # './training_checkpoints/ckpt_30'\n",
        "model.load_weights('ckpt_15')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrUScPmEwAtd",
        "colab_type": "text"
      },
      "source": [
        "## Text Generating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvQyWpjQvoPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 50\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in tqdm(range(num_generate)):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ZTmKkcdLqv",
        "colab_type": "code",
        "outputId": "fafcba44-6778-4d8e-b582-14608187be16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (1, None, 256)            9984      \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (1, None, 1024)           3935232   \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (1, None, 1024)           6294528   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (1, None, 39)             39975     \n",
            "=================================================================\n",
            "Total params: 10,279,719\n",
            "Trainable params: 10,279,719\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svyp2jP6vya_",
        "colab_type": "code",
        "outputId": "9d8a3fc8-424c-42b5-bae9-239082c7c631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"experts claim \"))\n",
        "\n",
        "print(generate_text(model, start_string=u\"yesterday in russia \"))\n",
        "\n",
        "print(generate_text(model, start_string=u\"the news coming from \"))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 42.87it/s]\n",
            "  2%|▏         | 1/50 [00:00<00:08,  5.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "experts claim 120000 role golden travel chapman jets pm rewarded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 43.98it/s]\n",
            "  2%|▏         | 1/50 [00:00<00:08,  6.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "yesterday in russia budget may spark biofuel plant move nt govt ridist\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 42.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the news coming from the charge lost voters on knights lead murray magi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2lwU0vZkdTl",
        "colab_type": "text"
      },
      "source": [
        "## Fake Headlines:\n",
        "\n",
        "experts claim 6000 fine quest over mass keelty plans pizza emerg\n",
        "\n",
        "yesterday in russia ballarat publisher on display in pakistan 15e pres\n",
        "\n",
        "the news coming from the head india to limit dire from polls on track f\n",
        "\n",
        "breaking news labor leader tightens overhaul eagles new interce\n",
        "\n",
        "obama set to be more ceremony recommended for remote sch\n",
        "\n",
        "schools request conviction since jailed final tensions imf\n",
        "\n",
        "government inquiry told aust maoiks for 10 year hollow highli\n",
        "\n",
        "president inspects japanese gymnastics chance stallone plead\n",
        "\n",
        "people to challenge bush secretary leader johnson new bhe\n",
        "\n",
        "celebrity leaders agree to meeting harbour bridge federal go\n",
        "\n",
        "united states to focus on climate uniform first cut bligh rack c\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzXYGdI-39qi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "369fe228-4355-4e36-b77f-327efce7fb57"
      },
      "source": [
        "print(generate_text(model, start_string=u\"united states \"))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 44.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "united states to focus on climate uniform first cut bligh rack c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjcuvbbWXpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}